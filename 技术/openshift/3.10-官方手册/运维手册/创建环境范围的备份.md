# 创建环境范围的备份
创建环境范围的备份涉及复制重要数据以帮助在发生实例崩溃或数据损坏时进行恢复。创建备份后，可以将它们还原到新安装的相关组件版本上。

在OKD中，可以在群集级别备份，将状态保存到单独的存储。环境备份的完整状态包括：

- 群集数据文件
- 每个 maser 的etcd数据
- API对象
- 镜像仓库
- 卷存储

定期执行备份以防止数据丢失。

以下过程描述了备份应用程序和OKD群集的一般方法。它不能考虑自定义要求。使用这些步骤作为群集的完整备份和还原过程的基础。您必须采取一切必要的预防措施以防止数据丢失。
	
无法保证备份和恢复。您负责备份自己的数据。

## 创建 master 节点备份
在对集群基础结构进行任何更改之前执行此备份过程，例如系统更新，升级或任何其他重大修改。定期备份数据，以确保在发生故障时最新数据可用。
### OKD文件
主实例运行重要的服务，例如API，控制器。该 `/etc/origin/master` 目录存储许多重要文件：

- 配置，API，控制器，服务等
- 安装生成的证书
- 所有与云提供商相关的配置
- 密钥和其他身份验证文件，例如，htpasswd
- 和更多

可以自定义OKD服务，例如提高日志级别或使用代理。配置文件存储在 `/etc/sysconfig` 目录中。

因为 master 服务器也是节点，所以备份整个 `/etc/origin` 目录。
### 步骤
	每个 master 节点必须执行以下步骤
1. 创建 master 主机配置文件的备份

		$ MYBACKUPDIR=/backup/$(hostname)/$(date +%Y%m%d)
		$ sudo mkdir -p ${MYBACKUPDIR}/etc/sysconfig
		$ sudo cp -aR /etc/origin ${MYBACKUPDIR}/etc
		$ sudo cp -aR /etc/sysconfig/atomic-* ${MYBACKUPDIR}/etc/sysconfig/
		
		# 配置文件存储在 /etc/sysconfig/atomic-openshift-master-api 和 /etc/sysconfig/atomic-openshift-master-controllers
		# /etc/origin/master/ca.serial.txt 文件仅在 Ansible 主机清单中列出的第一个 master 服务器上生成。如果弃用第一个 master 主机，请将 /etc/origin/master/ca.serial.txt 该文件复制到其余 master 主机
- 规划备份时需要考虑的其他重要文件包括
 
 文件名|描述
 ---|---
 /etc/cni/*|容器 sdn
 /etc/sysconfig/iptables|当前规则
 /etc/sysconfig/docker-storage-setup|container-storage-setup 容器存储设置文件
 /etc/sysconfig/docker|docker 配置文件
 /etc/sysconfig/docker-network|网络配置（即MTU）
 /etc/sysconfig/docker-storage|存储配置（生成container-storage-setup）
 /etc/dnsmasq.conf 和 /etc/dnsmasq.d/|dnsmasq 配置文件
 /etc/sysconfig/flanneld|flannel 配置文件
 /etc/pki/ca-trust/source/anchors/|添加到系统的证书(如外部的镜像仓库)
 
 创建这些文件的备份
 
		$ MYBACKUPDIR=/backup/$(hostname)/$(date +%Y%m%d)
		$ sudo mkdir -p ${MYBACKUPDIR}/etc/sysconfig
		$ sudo mkdir -p ${MYBACKUPDIR}/etc/pki/ca-trust/source/anchors
		$ sudo cp -aR /etc/sysconfig/{iptables,docker-*,flanneld} \
		    ${MYBACKUPDIR}/etc/sysconfig/
		$ sudo cp -aR /etc/dnsmasq* /etc/cni ${MYBACKUPDIR}/etc/
		$ sudo cp -aR /etc/pki/ca-trust/source/anchors/* \
		    ${MYBACKUPDIR}/etc/pki/ca-trust/source/anchors/
- 如果意外删除了包，或者需要重新生成 rpm 包中包含的文件，则在系统上安装包列表可能很有用。

		如果使用Red Hat Satellite功能（例如内容视图或事实存储），请提供适当的机制来重新安装缺少的软件包以及系统中安装的软件包的历史数据。

要创建系统中安装的当前包的列表

	$ MYBACKUPDIR=/backup/$(hostname)/$(date +%Y%m%d)
	$ sudo mkdir -p ${MYBACKUPDIR}
	$ rpm -qa | sort | sudo tee $MYBACKUPDIR/packages.txt
- 如果使用了前面的步骤，则备份目录中会出现以下文件

		$ MYBACKUPDIR=/backup/$(hostname)/$(date +%Y%m%d)
		$ sudo find ${MYBACKUPDIR} -mindepth 1 -type f -printf '%P\n'
		etc/sysconfig/atomic-openshift-master
		etc/sysconfig/atomic-openshift-master-api
		etc/sysconfig/atomic-openshift-master-controllers
		etc/sysconfig/atomic-openshift-node
		etc/sysconfig/flanneld
		etc/sysconfig/iptables
		etc/sysconfig/docker-network
		etc/sysconfig/docker-storage
		etc/sysconfig/docker-storage-setup
		etc/sysconfig/docker-storage-setup.rpmnew
		etc/origin/master/ca.crt
		etc/origin/master/ca.key
		etc/origin/master/ca.serial.txt
		etc/origin/master/ca-bundle.crt
		etc/origin/master/master.proxy-client.crt
		etc/origin/master/master.proxy-client.key
		etc/origin/master/service-signer.crt
		etc/origin/master/service-signer.key
		etc/origin/master/serviceaccounts.private.key
		etc/origin/master/serviceaccounts.public.key
		etc/origin/master/openshift-master.crt
		etc/origin/master/openshift-master.key
		etc/origin/master/openshift-master.kubeconfig
		etc/origin/master/master.server.crt
		etc/origin/master/master.server.key
		etc/origin/master/master.kubelet-client.crt
		etc/origin/master/master.kubelet-client.key
		etc/origin/master/admin.crt
		etc/origin/master/admin.key
		etc/origin/master/admin.kubeconfig
		etc/origin/master/etcd.server.crt
		etc/origin/master/etcd.server.key
		etc/origin/master/master.etcd-client.key
		etc/origin/master/master.etcd-client.csr
		etc/origin/master/master.etcd-client.crt
		etc/origin/master/master.etcd-ca.crt
		etc/origin/master/policy.json
		etc/origin/master/scheduler.json
		etc/origin/master/htpasswd
		etc/origin/master/session-secrets.yaml
		etc/origin/master/openshift-router.crt
		etc/origin/master/openshift-router.key
		etc/origin/master/registry.crt
		etc/origin/master/registry.key
		etc/origin/master/master-config.yaml
		etc/origin/generated-configs/master-master-1.example.com/master.server.crt
		...[OUTPUT OMITTED]...
		etc/origin/cloudprovider/openstack.conf
		etc/origin/node/system:node:master-0.example.com.crt
		etc/origin/node/system:node:master-0.example.com.key
		etc/origin/node/ca.crt
		etc/origin/node/system:node:master-0.example.com.kubeconfig
		etc/origin/node/server.crt
		etc/origin/node/server.key
		etc/origin/node/node-dnsmasq.conf
		etc/origin/node/resolv.conf
		etc/origin/node/node-config.yaml
		etc/origin/node/flannel.etcd-client.key
		etc/origin/node/flannel.etcd-client.csr
		etc/origin/node/flannel.etcd-client.crt
		etc/origin/node/flannel.etcd-ca.crt
		etc/pki/ca-trust/source/anchors/openshift-ca.crt
		etc/pki/ca-trust/source/anchors/registry-ca.crt
		etc/dnsmasq.conf
		etc/dnsmasq.d/origin-dns.conf
		etc/dnsmasq.d/origin-upstream-dns.conf
		etc/dnsmasq.d/node-dnsmasq.conf
		packages.txt
- 然后进行压缩归档

		$ MYBACKUPDIR=/backup/$(hostname)/$(date +%Y%m%d)
		$ sudo tar -zcvf /backup/$(hostname)-$(date +%Y%m%d).tar.gz $MYBACKUPDIR
		$ sudo rm -Rf ${MYBACKUPDIR}

要从头创建任何这些文件，`openshift-ansible-contrib` 存储库包含 `backup_master_node.sh`执行前面步骤的脚本。该脚本在运行脚本的主机上创建一个目录，并复制前面提到的所有文件。

可以在每个主主机上运行脚本：

	$ mkdir ~/git
	$ cd ~/git
	$ git clone https://github.com/openshift/openshift-ansible-contrib.git
	$ cd openshift-ansible-contrib/reference-architecture/day2ops/scripts
	$ ./backup_master_node.sh -h

## 创建计算节点备份
创建计算节点备份是备份 master 主机的另一种用例。由于 master 主机包含许多重要文件，因此强烈建议创建备份。但是，节点的性质是在故障转移的情况下在节点上复制任何特殊内容，并且它们通常不包含运行环境所必需的数据。如果节点的备份包含运行环境所必需的内容，则建议创建备份。

备份过程将在对基础结构进行任何更改之前执行，例如系统更新，升级或任何其他重大修改。应定期执行备份，以确保在发生故障时可获得最新数据。
### OKD文件
计算节点实例以 pod 的形式运行应用程序，pod基于容器。该 `/etc/origin/` 和 `/etc/origin/node` 目录房子重要文件，如：

- 计算节点服务的配置
- 安装生成的证书
- 与云提供商相关的配置
- 密钥和其他身份验证文件，例如 dnsmasq 配置

可以自定义 OKD 服务以增加日志级别，使用代理等，并且配置文件存储在 `/etc/sysconfig`目录中。

### 步骤
1. 创建节点配置文件的备份

		$ MYBACKUPDIR=/backup/$(hostname)/$(date +%Y%m%d)
		$ sudo mkdir -p ${MYBACKUPDIR}/etc/sysconfig
		$ sudo cp -aR /etc/origin ${MYBACKUPDIR}/etc
		$ sudo cp -aR /etc/sysconfig/atomic-openshift-node ${MYBACKUPDIR}/etc/sysconfig/
- 使用在规划备份策略时必须考虑的特定文件，包括

	文件名|描述
	 ---|---
	 /etc/cni/*|容器 sdn
	 /etc/sysconfig/iptables|当前规则
	 /etc/sysconfig/docker-storage-setup|container-storage-setup 容器存储设置文件
	 /etc/sysconfig/docker|docker 配置文件
	 /etc/sysconfig/docker-network|网络配置（即MTU）
	 /etc/sysconfig/docker-storage|存储配置（生成container-storage-setup）
	 /etc/dnsmasq.conf 和 /etc/dnsmasq.d/|dnsmasq 配置文件
	 /etc/sysconfig/flanneld|flannel 配置文件
	 /etc/pki/ca-trust/source/anchors/|添加到系统的证书(如外部的镜像仓库)

	要创建这些文件
	
		$ MYBACKUPDIR=/backup/$(hostname)/$(date +%Y%m%d)
		$ sudo mkdir -p ${MYBACKUPDIR}/etc/sysconfig
		$ sudo mkdir -p ${MYBACKUPDIR}/etc/pki/ca-trust/source/anchors
		$ sudo cp -aR /etc/sysconfig/{iptables,docker-*,flanneld} \
		    ${MYBACKUPDIR}/etc/sysconfig/
		$ sudo cp -aR /etc/dnsmasq* /etc/cni ${MYBACKUPDIR}/etc/
		$ sudo cp -aR /etc/pki/ca-trust/source/anchors/* \
		    ${MYBACKUPDIR}/etc/pki/ca-trust/source/anchors/ 
- 如果意外删除了包，或者rpm 应该还原包中包含的文件，那么 rhel 在系统上安装包列表可能会很有用。

	要创建rhel系统中安装的当前包的列表：
	
		$ MYBACKUPDIR=/backup/$(hostname)/$(date +%Y%m%d)
		$ sudo mkdir -p ${MYBACKUPDIR}
		$ rpm -qa | sort | sudo tee $MYBACKUPDIR/packages.txt
- 备份文件

		$ MYBACKUPDIR=/backup/$(hostname)/$(date +%Y%m%d)
		$ sudo find ${MYBACKUPDIR} -mindepth 1 -type f -printf '%P\n'
		etc/sysconfig/atomic-openshift-node
		etc/sysconfig/flanneld
		etc/sysconfig/iptables
		etc/sysconfig/docker-network
		etc/sysconfig/docker-storage
		etc/sysconfig/docker-storage-setup
		etc/sysconfig/docker-storage-setup.rpmnew
		etc/origin/node/system:node:app-node-0.example.com.crt
		etc/origin/node/system:node:app-node-0.example.com.key
		etc/origin/node/ca.crt
		etc/origin/node/system:node:app-node-0.example.com.kubeconfig
		etc/origin/node/server.crt
		etc/origin/node/server.key
		etc/origin/node/node-dnsmasq.conf
		etc/origin/node/resolv.conf
		etc/origin/node/node-config.yaml
		etc/origin/node/flannel.etcd-client.key
		etc/origin/node/flannel.etcd-client.csr
		etc/origin/node/flannel.etcd-client.crt
		etc/origin/node/flannel.etcd-ca.crt
		etc/origin/cloudprovider/openstack.conf
		etc/pki/ca-trust/source/anchors/openshift-ca.crt
		etc/pki/ca-trust/source/anchors/registry-ca.crt
		etc/dnsmasq.conf
		etc/dnsmasq.d/origin-dns.conf
		etc/dnsmasq.d/origin-upstream-dns.conf
		etc/dnsmasq.d/node-dnsmasq.conf
		packages.txt
	压缩
	
		$ MYBACKUPDIR=/backup/$(hostname)/$(date +%Y%m%d)
		$ sudo tar -zcvf /backup/$(hostname)-$(date +%Y%m%d).tar.gz $MYBACKUPDIR
		$ sudo rm -Rf ${MYBACKUPDIR}

## 备份镜像仓库证书
如果使用[外部镜像仓库](https://docs.okd.io/3.10/install_config/registry/securing_and_exposing_registry.html#exposing-the-registry)，则必须保存所有镜像仓库。镜像仓库默认是安全的。

	必须在每个群集节点上执行以下步骤。
步骤

1. 备份镜像仓库证书

		# cd /etc/docker/certs.d/
		# tar cf /tmp/docker-registry-certs-$(hostname).tar *
- 将备份移动到外部位置

	使用一个或多个[外部安全镜像仓库](https://docs.okd.io/3.10/install_config/registry/securing_and_exposing_registry.html#exposing-the-registry)时，任何提取或推送镜像的主机都必须信任镜像仓库证书才能运行pod。

## 备份其他安装文件
备份用于安装集群的文件

步骤

1. 由于还原过程涉及完全重新安装的需要，因此请保存初始安装中使用的所有文件。这些文件可能包括：
	- 来自[群集安装](https://docs.okd.io/3.10/install/running_install.html#install-running-installation-playbooks)的 Ansible playbooks和inventory文件
	- 来自[离线安装](https://docs.okd.io/3.10/install/disconnected_install.html#install-config-install-disconnected-install)方法的 `/etc/yum.repos.d/ose.repo`
- 备份安装后步骤的过程。某些安装可能涉及安装程序中未包含的步骤。这些步骤可能包括对OKD控制之外的服务的更改或监视代理等额外服务的安装。高级安装程序尚不支持的其他配置也可能会受到影响，例如使用多个身份验证提供程序。

## 备份应用程序数据
在许多情况下，假设 `rsync` 已安装在容器镜像中，可以使用该 `oc rsync` 命令备份应用程序数据。Red Hat rhel7 基本镜像包含 `rsync`。因此，所有基于rhel7的镜像都包含它。请参阅[CLI操作的故障排除和调试 -rsync](https://docs.okd.io/3.10/cli_reference/basic_cli_operations.html#cli-operations-rsync)。

	这是应用程序数据的通用备份，不考虑特定于应用程序的备份过程，例如，数据库系统的特殊导出和导入过程。

根据使用的持久卷的类型，可能存在其他备份方式，例如Cinder，NFS或Gluster。

备份的路径也是特定于应用程序的。可以通过在 `deploymentconfig` 查看中的 `mountPath` 卷来确定要备份的路径。

	只有在应用程序 pod 运行时，才能执行此类应用程序数据备份。
步骤(jenkins 部署演示)

1. `mountPath` 从以下位置获取应用程序数据 `deploymentconfig`

		$ oc get dc/jenkins -o jsonpath='{ .spec.template.spec.containers[?(@.name=="jenkins")].volumeMounts[?(@.name=="jenkins-data")].mountPath }'
		/var/lib/jenkins
2. 获取当前正在运行的 pod 的名称

		$ oc get pod --selector=deploymentconfig=jenkins -o jsonpath='{ .metadata.name }'
		jenkins-1-37nux
3. 使用该 `oc rsync` 命令复制应用程序数据

		$ oc rsync jenkins-1-37nux:/var/lib/jenkins /tmp/

## etcd备份
etcd 是所有对象定义的关键值存储，以及持久主状态。其他组件注意变化，然后使自己进入所需的状态。

3.5之前版本使用 etcd 版本 v2，而3.5及更高版本使用版本 v3。etcd 的两个版本之间的数据模型是不同的。etcd v3 可以同时使用 v2 和 v3 数据模型，而 etcd v2 只能使用 v2 数据模型。在 etcd v3 服务器中，v2 和 v3 数据存储并行存在且是独立的。

对于 v2 和 v3 操作，可以使用 `ETCDCTL_API` 环境变量来使用正确的API：

	$ etcdctl -v
	etcdctl version: 3.2.5
	API version: 2
	$ ETCDCTL_API=3 etcdctl version
	etcdctl version: 3.2.5
	API version: 3.2
有关如何迁移到 v3 的信息，请参阅[3.7文档中的迁移etcd数据v2到v3](https://docs.openshift.com/container-platform/3.7/upgrading/migrating_etcd.html)部分。

etcd 备份过程由两个不同的过程组成

- 配置备份

	包括所需的etcd配置和证书
- 数据备份

	包括v2和v3数据模型。

可以在任何连接到 etcd 群集的主机上执行数据备份过程，其中提供了正确的证书，以及 `etcdctl` 安装工具的位置。

	必须将备份文件复制到外部系统，最好是在集群环境之外，然后加密。

请注意，etcd 备份仍具有对当前存储卷的所有引用。当恢复 etcd 时，OKD开始在节点上启动先前的 pod 并重新连接相同的存储。此过程与从群集中删除节点并在其位置添加新节点的过程没有什么不同。附加到该节点的任何内容都会重新附加到重新安排到的任何节点上的 pod。

### 备份等待
备份 etcd 时，必须备份 etcd 配置文件和 etcd 数据。
#### 备份ETCD配置文件
要保留的 etcd 配置文件都存储在 `/etc/etcd` 运行 etcd 的实例的目录中。这包括 etcd 配置文件`/etc/etcd/etcd.conf` 和集群通信所需的证书。所有这些文件都是在安装时由 Ansible 安装程序生成的。

步骤

- 对于群集的每个 etcd 成员，请备份 etcd 配置，每个etcd集群成员上的证书和配置文件都是唯一的

		$ ssh master-0
		# mkdir -p /backup/etcd-config-$(date +%Y%m%d)/
		# cp -R /etc/etcd/ /backup/etcd-config-$(date +%Y%m%d)/

#### 备份 etcd 数据
##### 先觉条件
OKD安装程序创建别名以避免键入 `etcdctl2` 为etcd v2任务和 `etcdctl3etcd v3` 任务命名的所有标志。但是，`etcdctl3` 别名不会为 `etcdctl` 命令提供完整的端点列表 ，因此 `--endpoints` 必须提供包含所有端点的选项。

在备份 etcd 之前：

- `etcdctl` 应该提供二进制文件，或者在容器化安装中，`rhel7/etcd` 应该有容器
- 确保与 etcd 集群的连接(端口 `2379/tcp`)
- 确保连接到 etcd 集群的正确证书
	1.  要确保 etcd 群集正常工作，请检查其运行状况。
		- etcd v2

				# etcdctl --cert-file=/etc/etcd/peer.crt \
				          --key-file=/etc/etcd/peer.key \
				          --ca-file=/etc/etcd/ca.crt \
				          --peers="https://*master-0.example.com*:2379,\
				          https://*master-1.example.com*:2379,\
				          https://*master-2.example.com*:2379"\
				          cluster-health
				member 5ee217d19001 is healthy: got healthy result from https://192.168.55.12:2379
				member 2a529ba1840722c0 is healthy: got healthy result from https://192.168.55.8:2379
				member ed4f0efd277d7599 is healthy: got healthy result from https://192.168.55.13:2379
				cluster is healthy
		- etcd v3

				# ETCDCTL_API=3 etcdctl --cert="/etc/etcd/peer.crt" \
				          --key=/etc/etcd/peer.key \
				          --cacert="/etc/etcd/ca.crt" \
				          --endpoints="https://*master-0.example.com*:2379,\
				            https://*master-1.example.com*:2379,\
				            https://*master-2.example.com*:2379"
				            endpoint health
				https://master-0.example.com:2379 is healthy: successfully committed proposal: took = 5.011358ms
				https://master-1.example.com:2379 is healthy: successfully committed proposal: took = 1.305173ms
				https://master-2.example.com:2379 is healthy: successfully committed proposal: took = 1.388772ms
	- 检查成员列表
		- v2
		
				# etcdctl2 member list
				2a371dd20f21ca8d: name=master-1.example.com peerURLs=https://192.168.55.12:2380 clientURLs=https://192.168.55.12:2379 isLeader=false
				40bef1f6c79b3163: name=master-0.example.com peerURLs=https://192.168.55.8:2380 clientURLs=https://192.168.55.8:2379 isLeader=false
				95dc17ffcce8ee29: name=master-2.example.com peerURLs=https://192.168.55.13:2380 clientURLs=https://192.168.55.13:2379 isLeader=true
		- v3

				# etcdctl3 member list
				2a371dd20f21ca8d, started, master-1.example.com, https://192.168.55.12:2380, https://192.168.55.12:2379
				40bef1f6c79b3163, started, master-0.example.com, https://192.168.55.8:2380, https://192.168.55.8:2379
				95dc17ffcce8ee29, started, master-2.example.com, https://192.168.55.13:2380, https://192.168.55.13:2379

步骤

虽然该 `etcdctl backup` 命令用于执行备份，但 `etcd v3` 没有备份的概念。相反，可以使用该命令从实时成员获取快照，也可以从 etcd 数据目录中 `etcdctl snapshot save` 复制该 `member/snap/db` 文件。

该 `etcdctl backup` 命令会重写备份中包含的一些元数据，特别是节点ID和集群ID，这意味着在备份中，节点将丢失其以前的标识。要从备份重新创建群集，请创建新的单节点群集，然后将其余节点添加到群集。重写元数据以防止新节点加入现有集群。

- etcd 数据
	- v2 版本
		1. 停止所有 etcd

				# systemctl stop etcd.service
		2. 创建 etcd 数据备份并复制 etcd db 文件

				# mkdir -p /backup/etcd-$(date +%Y%m%d)
				# etcdctl2 backup \
				    --data-dir /var/lib/etcd \
				    --backup-dir /backup/etcd-$(date +%Y%m%d)
				# cp /var/lib/etcd/member/snap/db /backup/etcd-$(date +%Y%m%d)
		3. 启动 etcd 服务

				# systemctl start etcd.service
	- v3 版本

		从 v2 版本升级到 v3 版本的 etcd,需要备份2者数据。
		
		1. v3数据

				# systemctl show etcd --property=ActiveState,SubState
				# mkdir -p /backup/etcd-$(date +%Y%m%d)
				# etcdctl3 snapshot save /backup/etcd-$(date +%Y%m%d)/db
				Snapshot saved at /backup/etcd-<date>/db 
		2. v2 数据

				# systemctl stop etcd.service
				# etcdctl2 backup \
				    --data-dir /var/lib/etcd \
				    --backup-dir /backup/etcd-$(date +%Y%m%d)
				# cp /var/lib/etcd/member/snap/db /backup/etcd-$(date +%Y%m%d)
				# systemctl start etcd.service
				
			该 `etcdctl snapshot save` 命令要求 etcd 服务正在运行。

			在这些命令中，将 `/backup/etcd-<date>/` 创建一个目录，其中 `<date>`  表示当前日期，该日期必须是外部NFS共享，S3存储桶或任何外部存储位置。

			对于一体化集群，etcd 数据目录位于 `/var/lib/origin/openshift.local.etcd` 目录中。	

## 备份项目
创建所有相关数据的备份涉及导出所有重要信息，然后还原到新项目中。

Red Hat正在开发一个OKD项目备份和恢复工具。有关更多信息，请参阅以下错误 [bugzilla 1303205](https://bugzilla.redhat.com/show_bug.cgi?id=1303205)

步骤

1. 列出要备份的所有相关数据

		$ oc get all
		NAME         TYPE      FROM      LATEST
		bc/ruby-ex   Source    Git       1
		
		NAME               TYPE      FROM          STATUS     STARTED         DURATION
		builds/ruby-ex-1   Source    Git@c457001   Complete   2 minutes ago   35s
		
		NAME                 DOCKER REPO                                     TAGS      UPDATED
		is/guestbook         10.111.255.221:5000/myproject/guestbook         latest    2 minutes ago
		is/hello-openshift   10.111.255.221:5000/myproject/hello-openshift   latest    2 minutes ago
		is/ruby-22-centos7   10.111.255.221:5000/myproject/ruby-22-centos7   latest    2 minutes ago
		is/ruby-ex           10.111.255.221:5000/myproject/ruby-ex           latest    2 minutes ago
		
		NAME                 REVISION   DESIRED   CURRENT   TRIGGERED BY
		dc/guestbook         1          1         1         config,image(guestbook:latest)
		dc/hello-openshift   1          1         1         config,image(hello-openshift:latest)
		dc/ruby-ex           1          1         1         config,image(ruby-ex:latest)
		
		NAME                   DESIRED   CURRENT   READY     AGE
		rc/guestbook-1         1         1         1         2m
		rc/hello-openshift-1   1         1         1         2m
		rc/ruby-ex-1           1         1         1         2m
		
		NAME                  CLUSTER-IP       EXTERNAL-IP   PORT(S)             AGE
		svc/guestbook         10.111.105.84    <none>        3000/TCP            2m
		svc/hello-openshift   10.111.230.24    <none>        8080/TCP,8888/TCP   2m
		svc/ruby-ex           10.111.232.117   <none>        8080/TCP            2m
		
		NAME                         READY     STATUS      RESTARTS   AGE
		po/guestbook-1-c010g         1/1       Running     0          2m
		po/hello-openshift-1-4zw2q   1/1       Running     0          2m
		po/ruby-ex-1-build           0/1       Completed   0          2m
		po/ruby-ex-1-rxc74           1/1       Running     0          2m
- 将项目对象导出到文件 `.yaml`或 `.json`文件。
	- 要将项目对象导出到 `project.yaml` 文件中

			$ oc export all -o yaml> project.yaml
	- 要将项目对象导出到 `project.json` 文件中
	
			$ oc export all -o json> project.json
- 导出项目的 `role bindings，secrets， service accounts` 和 `persistent volume claims`

		$ for object in rolebindings serviceaccounts secrets imagestreamtags podpreset cms egressnetworkpolicies rolebindingrestrictions limitranges resourcequotas pvcs templates cronjobs statefulsets hpas deployments replicasets poddisruptionbudget endpoints
		do
		  oc export $object -o yaml > $object.yaml
		done
- 某些导出的对象可以依赖于特定的元数据或对项目中唯一ID的引用。这是对重新创建的对象的可用性的限制。

	使用时 `imagestreams`，a 的 `image` 参数 `deploymentconfig` 指向 `sha` 内部镜像仓库中镜像特定校验，该校验和在恢复的环境中不存在。
	
	例如，运行示例“ruby-ex” 
	
	`oc new-app centos/ruby-22-centos7~https://github.com/sclorg/ruby-ex.git` 创建一个 `imagestream ruby-ex` 使用内部镜像仓库来托管镜像
	
		$ oc get dc ruby-ex -o jsonpath="{.spec.template.spec.containers[].image}"
		10.111.255.221:5000/myproject/ruby-ex@sha256:880c720b23c8d15a53b01db52f7abdcbb2280e03f686a5c8edfef1a2a7b21cee
如果镜像不存在，导入 `deploymentconfig` 与导出 `oc export` 就会失败。

	要创建这些导出，请使用存储库 `project_export.sh` 中的 `openshift-ansible-contrib` 存储库，该存储库将在不同文件中创建所有项目对象。该脚本在运行脚本的主机上创建一个目录，其中包含项目名称和该项目json中每个对象类型的文件。

	该脚本运行在Linux上，并要求 jq 和 oc 安装命令，系统应登录到OKD环境，可以读取在该项目中的所有对象的用户。
	
		$ mkdir ~/git
		$ cd ~/git
		$ git clone https://github.com/openshift/openshift-ansible-contrib.git
		$ cd openshift-ansible-contrib/reference-architecture/day2ops/scripts
		$ ./project_export.sh <projectname>
	样例
	
		$ ./project_export.sh myproject
		Exporting namespace to project-demo/ns.json
		Exporting rolebindings to project-demo/rolebindings.json
		Exporting serviceaccounts to project-demo/serviceaccounts.json
		Exporting secrets to project-demo/secrets.json
		Exporting deploymentconfigs to project-demo/dc_*.json
		Patching DC...
		Exporting buildconfigs to project-demo/bcs.json
		Exporting builds to project-demo/builds.json
		Exporting imagestreams to project-demo/iss.json
		Exporting imagestreamtags to project-demo/imagestreamtags.json
		Exporting replicationcontrollers to project-demo/rcs.json
		Exporting services to project-demo/svc_*.json
		Exporting pods to project-demo/pods.json
		Exporting podpreset to project-demo/podpreset.json
		Exporting configmaps to project-demo/cms.json
		Exporting egressnetworkpolicies to project-demo/egressnetworkpolicies.json
		Exporting rolebindingrestrictions to project-demo/rolebindingrestrictions.json
		Exporting limitranges to project-demo/limitranges.json
		Exporting resourcequotas to project-demo/resourcequotas.json
		Exporting pvcs to project-demo/pvcs.json
		Exporting routes to project-demo/routes.json
		Exporting templates to project-demo/templates.json
		Exporting cronjobs to project-demo/cronjobs.json
		Exporting statefulsets to project-demo/statefulsets.json
		Exporting hpas to project-demo/hpas.json
		Exporting deployments to project-demo/deployments.json
		Exporting replicasets to project-demo/replicasets.json
		Exporting poddisruptionbudget to project-demo/poddisruptionbudget.json
- 执行后，查看文件以验证内容是否已正确导出,如果原始对象不存在，则导出时将创建空文件

		$ cd <projectname>
		$ ls -1
		bcs.json
		builds.json
		cms.json
		cronjobs.json
		dc_ruby-ex.json
		dc_ruby-ex_patched.json
		deployments.json
		egressnetworkpolicies.json
		endpoint_external-的mysql-service.json
		hpas.json
		imagestreamtags.json
		iss.json
		limitranges.json
		ns.json
		poddisruptionbudget.json
		podpreset.json
		pods.json
		pvcs.json
		rcs.json
		replicasets.json
		resourcequotas.json
		rolebindingrestrictions.json
		rolebindings.json
		routes.json
		secrets.json
		serviceaccounts.json
		statefulsets.json
		svc_external-的mysql-service.json
		svc_ruby-ex.json
		templates.json
		$ less bcs.json
		...
- 如果使用 `imagestreams`，脚本会修改 `deploymentconfig` 使用镜像引用而不是镜像 `sha`，创建 `json` 与使用 `_patched` 附录导出的文件不同的文件：

		$ diff dc_hello-openshift.json dc_hello-openshift_patched.json
		45c45
		<“image”：“docker.io/openshift/hello-openshift@sha256:42b59c869471a1b5fdacadf778667cecbaa79e002b7235f8091540ae612f0e14”，
		---
		>“image”：“hello-openshift：latest”，

该脚本目前不支持多个 pod，请谨慎使用

## 备份持久化卷申请
可以将容器内部的持久数据同步到服务器。

根据承载 OKD 环境的提供程序，还存在为备份和还原目的启动第三方快照服务的功能。由于OKD无法启动这些服务，因此本指南未介绍这些步骤。

有关特定应用程序的正确备份过程，请参阅任何产品文档。例如，复制 mysql 数据目录本身不会创建可用的备份。而是，运行关联应用程序的特定备份过程，然后同步任何数据。这包括使用OKD托管平台提供的快照解决方案。

步骤

1. 查看项目和pods

		$ oc get pods
		NAME           READY     STATUS      RESTARTS   AGE
		demo-1-build   0/1       Completed   0          2h
		demo-2-fxx6d   1/1       Running     0          1h
- 描述所需的 pod 以查找持久卷当前使用的卷

		$ oc describe pod demo-2-fxx6d
		Name:			demo-2-fxx6d
		Namespace:		test
		Security Policy:	restricted
		Node:			ip-10-20-6-20.ec2.internal/10.20.6.20
		Start Time:		Tue, 05 Dec 2017 12:54:34 -0500
		Labels:			app=demo
					deployment=demo-2
					deploymentconfig=demo
		Status:			Running
		IP:			172.16.12.5
		Controllers:		ReplicationController/demo-2
		Containers:
		  demo:
		    Container ID:	docker://201f3e55b373641eb36945d723e1e212ecab847311109b5cee1fd0109424217a
		    Image:		docker-registry.default.svc:5000/test/demo@sha256:0a9f2487a0d95d51511e49d20dc9ff6f350436f935968b0c83fcb98a7a8c381a
		    Image ID:		docker-pullable://docker-registry.default.svc:5000/test/demo@sha256:0a9f2487a0d95d51511e49d20dc9ff6f350436f935968b0c83fcb98a7a8c381a
		    Port:		8080/TCP
		    State:		Running
		      Started:		Tue, 05 Dec 2017 12:54:52 -0500
		    Ready:		True
		    Restart Count:	0
		    Volume Mounts:
		      */opt/app-root/src/uploaded from persistent-volume (rw)*
		      /var/run/secrets/kubernetes.io/serviceaccount from default-token-8mmrk (ro)
		    Environment Variables:	<none>
		...omitted...
	此输出显示持久数据位于 `/opt/app-root/src/uploaded` 目录中。
- 在本地复制数据

		$ oc rsync demo-2-fxx6d:/opt/app-root/src/uploaded ./demo-app
		receiving incremental file list
		uploaded/
		uploaded/ocp_sop.txt
		uploaded/lost+found/
		
		sent 38 bytes  received 190 bytes  152.00 bytes/sec
		total size is 32  speedup is 0.14
	该 `ocp_sop.txt` 文件将下载到本地系统，以备份软件或其他备份机制进行备份。

	如果在不需要使用的情况下启动一个 pod，也可以使用前面的步骤 `pvc`，但稍后决定一个 `pvc` 是必要的。可以保留数据，然后使用 restorate 进程填充新存储。
